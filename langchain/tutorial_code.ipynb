{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87df1602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLangchain AI Agent Tutorial\\nSubtopics:\\n- Langchain basics\\n- Langchain Memory, Tool usage\\n- RAG (Retrieval Augmented Generation)\\n- FastAPI backend (connect with Streamlit frontend)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Langchain AI Agent Tutorial\n",
    "Subtopics:\n",
    "- Langchain basics\n",
    "- Langchain Memory, Tool usage\n",
    "- RAG (Retrieval Augmented Generation)\n",
    "- FastAPI backend (connect with Streamlit frontend)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00f7ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langchain basics\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_classic.chains import LLMChain\n",
    "from langchain_classic.prompts import PromptTemplate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccb5b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG (Retrieval Augmented Generation)\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import numpy as np\n",
    "from langchain_classic.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdab3848",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d460d190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6e9f335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langchain LLM Response:  OpenAI is a research organization focused on developing artificial intelligence in a responsible and ethical manner. It was founded in 2015 by a group of entrepreneurs and researchers, including Elon Musk, Sam Altman, and Peter Thiel. OpenAI conducts research in various areas of artificial intelligence, including machine learning, robotics, and natural language processing, with the goal of creating safe and beneficial AI for all. Their research is open and transparent, and they often collaborate with other organizations and researchers in the field.\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI()\n",
    "prompt = PromptTemplate(input_variables=[\"question\"], template=\"Q: {question}\\nA:\")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "response = chain.run(question=\"What is OpenAI?\")\n",
    "print(\"Langchain LLM Response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc69a0b",
   "metadata": {},
   "source": [
    "Memory and Tool usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1eeb8bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Buffer: Human: Hello\n",
      "AI: Hi!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74257/1883185913.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"Hi!\"})\n",
    "print(\"Memory Buffer:\", memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6a2f177",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"How is weather?\"}, {\"output\": \"Good!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a92bf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Buffer: Human: Hello\n",
      "AI: Hi!\n",
      "Human: How is weather?\n",
      "AI: Good!\n"
     ]
    }
   ],
   "source": [
    "print(\"Memory Buffer:\", memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "365239df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple document list\n",
    "texts = [\"Langchain is a framework for developing applications powered by language models.\",\n",
    "         \"RAG stands for Retrieval Augmented Generation.\",\n",
    "         \"You can use Langchain with FastAPI and Streamlit.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b47aa7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_texts(texts, embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b0128eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer:  Retrieval Augmented Generation\n"
     ]
    }
   ],
   "source": [
    "answer = qa.run(\"What is RAG?\")\n",
    "print(\"RAG Answer:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cc09a0",
   "metadata": {},
   "source": [
    "FastAPI backend (see api.py for implementation)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
